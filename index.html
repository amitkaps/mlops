<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>MLOps</title>
    <!--MAIN CSS-->
    
    <script type="module" crossorigin src="/assets/index.f36b2abd.js"></script>
    <link rel="stylesheet" href="/assets/index.6b1c43e9.css">
  </head>
  <body>
    <header>
      <h1 class="title">Practical Machine Learning Operations </h1>
    </header>
    <main id="content"><article><h1><strong>Practical ML Operations (MLOps)</strong></h1><p>This is work in progress.</p><h2><em>Scope &amp; Session Plan</em></h2><ul><li><em>Day 1:</em> MLOps Landscape and Building Reproducible Prototype</li><li><em>Day 2:</em> Continuous Training - Data, Model, Experiments &amp; Testing</li><li><em>Day 3:</em> Continuous Deployment - Serving, Inference, Feedback &amp; System Performance</li></ul><hr><h3>Session 1: <a href="/introduction-concepts"><strong>Introduction &amp; Concepts</strong></a></h3><ul><li>Challenges for ML driven Operations in Production</li><li>Requirements: Reliable, Scalable, Maintainable, Adaptable</li><li>Considerations: Framing, Objectives, Constraints &amp; Phases</li><li>Thinking in Systems: Application, Business and Infrastructure</li></ul><h3>Session 2: <a href="/systems-operations"><strong>Systems &amp; Operations</strong></a></h3><ul><li>Current Landscape and Maturity Level for ML Ops</li><li>Define ML Ops: Requirements, Considerations, Interfaces, Data &amp; Model</li><li>Understand Process, Skills, and Tooling to move across Maturity Levels</li><li>View Case Studies and Best Practices of ML Ops from the Industry</li></ul><h3>Session 3: <strong>Prototype &amp; Modularize</strong></h3><ul><li>Build a basic task-focused ML model for the case problem</li><li>Create, build and deploy a local serving prototype ML system</li><li>Modularize the Prototype Code, Data and Model for improved iteration</li><li>Understand Trade-offs and Benefits of Modularized Approach</li></ul><h3>Session 4: <strong>Versioning &amp; Components</strong></h3><ul><li>Versioning in ML Ops: Workflow &amp; Components</li><li>Declarative Code, Data &amp; Model Design Patterns</li><li>Versioning: ML Code, Model Envelopes, Data Snapshots &amp; Artefacts</li><li>Create a Versioned System for the Case Example</li></ul><h3>Session 5: <strong>Organising &amp; Preparation</strong></h3><ul><li>Manage Data in ML Ops: Organize, Prepare &amp; Reproduce</li><li>Training Data Prep: Extraction, Sampling, Splitting &amp; Windowing</li><li>Component Setup: Labelling, Preprocessing, &amp; Augmentation</li><li>Modularise &amp; isolate components for data preparation</li></ul><h3>Session 6: <strong>Experiments &amp; Training</strong></h3><ul><li>Baselines: Heuristic-driven, Simple ML baselines</li><li>Setup for Rapid Experiments: Repeatable and Reproducible</li><li>Experiment Tracking: Model Parameters, Optimisation</li><li>Organise &amp; Package for Data, Compute, and Infrastructure needs</li></ul><h3>Session 7: <strong>Evaluation &amp; Metrics</strong></h3><ul><li>Coarse-grained vs Fine-grained Model Evaluation</li><li>Evaluation for Robustness: Stratification &amp; Slicing, Confidence</li><li>Metrics vs. Business Objectives &amp; Interpretations</li><li>Tracking evaluation metrics for coverage and failure cases</li></ul><h3>Session 8: <strong>Testing &amp; Validation</strong></h3><ul><li>Code Testing: Unit, Integration, System &amp; Acceptance</li><li>Data Testing: Schema, Expectations, Quality, Distribution Skew</li><li>Model Testing: Training, Evaluation, Inference &amp; Deployment</li><li>Behavioural Testing: Invariance, Functionality, Directionality</li></ul><h3>Session 9: <strong>Serving &amp; Inference</strong></h3><ul><li>Align Objectives and Interfaces for Serving e.g Latency</li><li>Inference Optimisation: Accelerators, Model Quantisation / Distillation</li><li>Design for Production: Packages, Executables and Artefacts</li><li>Thinking in Stages: Test, Canary, Development, Production</li></ul><h3>Session 10: <strong>Monitoring &amp; Feedback</strong></h3><ul><li>Performance monitoring and Post-Hoc Evaluation</li><li>Predictive monitoring: Delayed Outcomes, Importance Weighting</li><li>Measuring &amp; Locating Drift: Data (Label &amp; Feature), Concept</li><li>Feedback loop: Integrating with Application Logging and Monitoring</li></ul><h3>Session 11: <strong>Levels &amp; Practice</strong></h3><ul><li>Advanced Levels of Maturity for MLOps</li><li>Dataset Management: Catalogs, Quality, Lineage</li><li>Feature Stores and Pipeline Orchestration</li><li>Continuous Monitoring and Automated Triggering</li></ul><h3>Session 12: <strong>Best Practices</strong></h3><ul><li>Advanced Case Study of a Successful MLOps</li><li>Review of Best Practices for MLOps in Production</li><li>Moving towards Continual Learning Data-centric Systems</li><li>Learning Path and Way Forward</li></ul></article></main>
    <footer></footer>
    <!--MAIN SCRIPT-->
    
    <!--Development SCRIPT-->
    
  </body>
</html>